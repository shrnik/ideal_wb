{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df1b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3100, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3155, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3367, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3612, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3672, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/0w/myt_z3n1465gbt0kfx4qm7pc0000gn/T/ipykernel_2942/4035530276.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/shrenikborad/personal/worldbank/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, DataCollatorWithPadding\n",
    ")\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81691ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid labels: Index(['randomised controlled trial', 'fixed effects (incl. did)', 'other',\n",
      "       'statistical matching', 'instrumental variable estimation',\n",
      "       'regression discontinuity design', 'interrupted time series analysis',\n",
      "       'synthetic control'],\n",
      "      dtype='object', name='label')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/shrenikborad/personal/worldbank/data/initial_data.csv\")\n",
    "df = df.dropna(subset=['Title', 'Abstract'])\n",
    "df['text'] = \"[TITLE] \" + df['Title'] + \" [ABSTRACT] \" + df['Abstract']\n",
    "\n",
    "df[\"text\"].head()\n",
    "\n",
    "\n",
    "df['label'] = df['Method'].fillna(\"other\")\n",
    "df['label'] = df['Method'].apply(\n",
    "    lambda x: x.strip().lower() if isinstance(x, str) and x.strip() else \"other\")\n",
    "\n",
    "counts = df['label'].value_counts()\n",
    "valid_labels = counts[counts >= 2].index \n",
    "print(f\"Valid labels: {valid_labels}\")\n",
    "df = df[df['label'].isin(valid_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f679e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Map: {'fixed effects (incl. did)': np.int64(0), 'instrumental variable estimation': np.int64(1), 'interrupted time series analysis': np.int64(2), 'other': np.int64(3), 'randomised controlled trial': np.int64(4), 'regression discontinuity design': np.int64(5), 'statistical matching': np.int64(6), 'synthetic control': np.int64(7)}\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_id'] = label_encoder.fit_transform(df['label'])\n",
    "df['label_id'] = df['label_id'].astype(int)\n",
    "# Save label mapping (optional)\n",
    "label_map = dict(zip(label_encoder.classes_,\n",
    "                 label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Map:\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2deae6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.2, stratify=df['label_id'], random_state=42\n",
    ")\n",
    "\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.5, stratify=temp_df['label_id'], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c6ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m MODEL_NAME = \u001b[33m\"\u001b[39m\u001b[33mallenai/scibert_scivocab_uncased\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize_function\u001b[39m(examples):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4574\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4565\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4567\u001b[39m     (\n\u001b[32m   4568\u001b[39m         model,\n\u001b[32m   4569\u001b[39m         missing_keys,\n\u001b[32m   4570\u001b[39m         unexpected_keys,\n\u001b[32m   4571\u001b[39m         mismatched_keys,\n\u001b[32m   4572\u001b[39m         offload_index,\n\u001b[32m   4573\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4574\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4590\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4592\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4593\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4833\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   4830\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(state_dict.keys())\n\u001b[32m   4831\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4832\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m4833\u001b[39m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m.keys()\n\u001b[32m   4834\u001b[39m     )\n\u001b[32m   4836\u001b[39m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[32m   4837\u001b[39m prefix = model.base_model_prefix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:554\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[39m\n\u001b[32m    552\u001b[39m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/personal/worldbank/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1417\u001b[39m, in \u001b[36mcheck_torch_load_is_safe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_torch_load_is_safe\u001b[39m():\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[33m\"\u001b[39m\u001b[33m2.6\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1417\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1418\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1419\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1420\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwhen loading files with safetensors.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1421\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1422\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "MODEL_NAME = \"allenai/scibert_scivocab_uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=num_labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "\n",
    "# Step 3: Convert to HuggingFace Datasets\n",
    "train_ds = Dataset.from_pandas(train_df[['text', 'label_id']])\n",
    "val_ds = Dataset.from_pandas(val_df[['text', 'label_id']])\n",
    "test_ds = Dataset.from_pandas(test_df[['text', 'label_id']])\n",
    "\n",
    "train_ds = train_ds.map(tokenize_function, batched=True)\n",
    "train_ds = train_ds.rename_column(\"label_id\", \"labels\")\n",
    "val_ds = val_ds.map(tokenize_function, batched=True)\n",
    "val_ds = val_ds.rename_column(\"label_id\", \"labels\")\n",
    "test_ds = test_ds.map(tokenize_function, batched=True)\n",
    "test_ds = test_ds.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    # Print classification report automatically\n",
    "    print(\"\\nClassification Report:\")\n",
    "    target_names = label_encoder.classes_  # adjust as needed\n",
    "    print(classification_report(labels, preds, target_names=target_names))\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average='macro'),\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./dev-econ-classifier\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Step 7: Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Step 8: Evaluate on test set\n",
    "results = trainer.evaluate(test_ds)\n",
    "print(\"Test Results:\", results)\n",
    "\n",
    "# Optional: Save model\n",
    "model.save_pretrained(\"method-classifier-wb\")\n",
    "tokenizer.save_pretrained(\"method-classifier-wb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
